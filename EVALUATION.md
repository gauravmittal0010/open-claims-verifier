# Evaluation Criteria

This project is a design hypothesis.

The hypothesis:

A system can use AI to expose uncertainty in public claims without becoming an authority itself.

This project should be considered unsuccessful if any of the following occur:

1. Users begin treating the system as a source of final truth.
2. The system requires ranking, scoring, or verdict outputs to be useful.
3. The system cannot function without centralized control.
4. The model encourages persuasion rather than understanding.
5. The uncertainty outputs are ignored in favor of summaries.

If these conditions are necessary for adoption, the design assumption is wrong.

The goal is not adoption at any cost.

The goal is to determine whether a non-authoritative AI tool is possible at all.